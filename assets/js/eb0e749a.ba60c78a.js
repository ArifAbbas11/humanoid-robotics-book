"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[5708],{8173:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>s,metadata:()=>t,toc:()=>c});var i=r(4848),o=r(8453);const s={},a="Mini-Project: Configuring Sensors for a Humanoid Robot",t={id:"simulation/mini-project",title:"Mini-Project: Configuring Sensors for a Humanoid Robot",description:"Overview",source:"@site/docs/simulation/mini-project.md",sourceDirName:"simulation",slug:"/simulation/mini-project",permalink:"/humanoid-robotics-book/simulation/mini-project",draft:!1,unlisted:!1,editUrl:"https://github.com/ArifAbbas11/humanoid-robotics-book/tree/main/docs/simulation/mini-project.md",tags:[],version:"current",frontMatter:{},sidebar:"bookSidebar",previous:{title:"Sensor Configuration",permalink:"/humanoid-robotics-book/simulation/sensor-configuration"},next:{title:"Troubleshooting Simulation Issues",permalink:"/humanoid-robotics-book/simulation/troubleshooting"}},l={},c=[{value:"Overview",id:"overview",level:2},{value:"Prerequisites",id:"prerequisites",level:2},{value:"Step 1: Create the Robot Model with Sensors",id:"step-1-create-the-robot-model-with-sensors",level:2},{value:"Step 2: Create a Launch File",id:"step-2-create-a-launch-file",level:2},{value:"Step 3: Create a Sensor Processing Node",id:"step-3-create-a-sensor-processing-node",level:2},{value:"Step 4: Build and Run the Simulation",id:"step-4-build-and-run-the-simulation",level:2},{value:"Step 5: Verify Sensor Data",id:"step-5-verify-sensor-data",level:2},{value:"Expected Results",id:"expected-results",level:2},{value:"Troubleshooting",id:"troubleshooting",level:2},{value:"Next Steps",id:"next-steps",level:2}];function u(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,o.RP)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h1,{id:"mini-project-configuring-sensors-for-a-humanoid-robot",children:"Mini-Project: Configuring Sensors for a Humanoid Robot"}),"\n",(0,i.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,i.jsx)(n.p,{children:"In this mini-project, you'll configure multiple sensors on a simulated humanoid robot and implement basic perception capabilities."}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Completed previous simulation sections"}),"\n",(0,i.jsx)(n.li,{children:"Gazebo installed and configured"}),"\n",(0,i.jsx)(n.li,{children:"Basic understanding of URDF and ROS 2"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"step-1-create-the-robot-model-with-sensors",children:"Step 1: Create the Robot Model with Sensors"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"humanoid_with_sensors.urdf.xacro"})," in your robot package:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\r\n<robot xmlns:xacro="http://www.ros.org/wiki/xacro" name="humanoid_robot">\r\n\r\n  \x3c!-- Base link --\x3e\r\n  <link name="base_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.4"/>\r\n      </geometry>\r\n      <material name="blue">\r\n        <color rgba="0 0 1 0.8"/>\r\n      </material>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.3 0.2 0.4"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="10"/>\r\n      <inertia ixx="1" ixy="0" ixz="0" iyy="1" iyz="0" izz="1"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  \x3c!-- Head with camera --\x3e\r\n  <link name="head">\r\n    <visual>\r\n      <geometry>\r\n        <sphere radius="0.1"/>\r\n      </geometry>\r\n      <material name="white">\r\n        <color rgba="1 1 1 0.8"/>\r\n      </material>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <sphere radius="0.1"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="1"/>\r\n      <inertia ixx="0.004" ixy="0" ixz="0" iyy="0.004" iyz="0" izz="0.004"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="neck_joint" type="revolute">\r\n    <parent link="base_link"/>\r\n    <child link="head"/>\r\n    <origin xyz="0 0 0.3" rpy="0 0 0"/>\r\n    <axis xyz="0 1 0"/>\r\n    <limit lower="-0.5" upper="0.5" effort="100" velocity="1"/>\r\n  </joint>\r\n\r\n  \x3c!-- Camera in the head --\x3e\r\n  <link name="camera_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.05 0.05 0.05"/>\r\n      </geometry>\r\n      <material name="black">\r\n        <color rgba="0 0 0 0.8"/>\r\n      </material>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.05 0.05 0.05"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.1"/>\r\n      <inertia ixx="0.0001" ixy="0" ixz="0" iyy="0.0001" iyz="0" izz="0.0001"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="camera_joint" type="fixed">\r\n    <parent link="head"/>\r\n    <child link="camera_link"/>\r\n    <origin xyz="0.05 0 0" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- IMU in the torso --\x3e\r\n  <link name="imu_link">\r\n    <visual>\r\n      <geometry>\r\n        <box size="0.02 0.02 0.02"/>\r\n      </geometry>\r\n    </visual>\r\n    <collision>\r\n      <geometry>\r\n        <box size="0.02 0.02 0.02"/>\r\n      </geometry>\r\n    </collision>\r\n    <inertial>\r\n      <mass value="0.05"/>\r\n      <inertia ixx="0.000001" ixy="0" ixz="0" iyy="0.000001" iyz="0" izz="0.000001"/>\r\n    </inertial>\r\n  </link>\r\n\r\n  <joint name="imu_joint" type="fixed">\r\n    <parent link="base_link"/>\r\n    <child link="imu_link"/>\r\n    <origin xyz="0 0 0" rpy="0 0 0"/>\r\n  </joint>\r\n\r\n  \x3c!-- Gazebo plugins for sensors --\x3e\r\n  <gazebo reference="camera_link">\r\n    <sensor type="camera" name="camera1">\r\n      <update_rate>30.0</update_rate>\r\n      <camera name="head">\r\n        <horizontal_fov>1.3962634</horizontal_fov>\r\n        <image>\r\n          <width>640</width>\r\n          <height>480</height>\r\n          <format>R8G8B8</format>\r\n        </image>\r\n        <clip>\r\n          <near>0.02</near>\r\n          <far>300</far>\r\n        </clip>\r\n        <noise>\r\n          <type>gaussian</type>\r\n          <mean>0.0</mean>\r\n          <stddev>0.007</stddev>\r\n        </noise>\r\n      </camera>\r\n      <plugin name="camera_controller" filename="libgazebo_ros_camera.so">\r\n        <frame_name>camera_link</frame_name>\r\n        <topic_name>image_raw</topic_name>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n  <gazebo reference="imu_link">\r\n    <sensor type="imu" name="imu_sensor">\r\n      <always_on>true</always_on>\r\n      <update_rate>100</update_rate>\r\n      <visualize>false</visualize>\r\n      <plugin filename="libgazebo_ros_imu_sensor.so" name="imu_plugin">\r\n        <topicName>imu</topicName>\r\n        <bodyName>base_link</bodyName>\r\n        <updateRateHZ>100.0</updateRateHZ>\r\n        <gaussianNoise>0.01</gaussianNoise>\r\n        <xyzOffset>0 0 0</xyzOffset>\r\n        <rpyOffset>0 0 0</rpyOffset>\r\n        <frameName>imu_link</frameName>\r\n      </plugin>\r\n    </sensor>\r\n  </gazebo>\r\n\r\n</robot>\n'})}),"\n",(0,i.jsx)(n.h2,{id:"step-2-create-a-launch-file",children:"Step 2: Create a Launch File"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"launch/sensor_demo.launch.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\r\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\r\nfrom launch.conditions import IfCondition\r\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\r\nfrom launch.substitutions import LaunchConfiguration, PathJoinSubstitution\r\nfrom launch_ros.actions import Node\r\nfrom launch_ros.substitutions import FindPackageShare\r\n\r\ndef generate_launch_description():\r\n    ld = LaunchDescription()\r\n\r\n    # Launch arguments\r\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\r\n    show_rviz = LaunchConfiguration('show_rviz', default='true')\r\n\r\n    ld.add_action(DeclareLaunchArgument(\r\n        'use_sim_time',\r\n        default_value='true',\r\n        description='Use simulation (Gazebo) clock if true'))\r\n\r\n    ld.add_action(DeclareLaunchArgument(\r\n        'show_rviz',\r\n        default_value='true',\r\n        description='Show RViz if true'))\r\n\r\n    # Launch Gazebo\r\n    gazebo = IncludeLaunchDescription(\r\n        PythonLaunchDescriptionSource([\r\n            PathJoinSubstitution([\r\n                FindPackageShare('gazebo_ros'),\r\n                'launch',\r\n                'gazebo.launch.py'\r\n            ])\r\n        ]),\r\n    )\r\n    ld.add_action(gazebo)\r\n\r\n    # Spawn robot in Gazebo\r\n    spawn_entity = Node(\r\n        package='gazebo_ros',\r\n        executable='spawn_entity.py',\r\n        arguments=[\r\n            '-topic', 'robot_description',\r\n            '-entity', 'humanoid_robot',\r\n            '-x', '0', '-y', '0', '-z', '0.5'\r\n        ],\r\n        output='screen'\r\n    )\r\n    ld.add_action(spawn_entity)\r\n\r\n    # Robot state publisher\r\n    robot_state_publisher = Node(\r\n        package='robot_state_publisher',\r\n        executable='robot_state_publisher',\r\n        name='robot_state_publisher',\r\n        output='screen',\r\n        parameters=[{'use_sim_time': use_sim_time}]\r\n    )\r\n    ld.add_action(robot_state_publisher)\r\n\r\n    # Joint state publisher\r\n    joint_state_publisher = Node(\r\n        package='joint_state_publisher',\r\n        executable='joint_state_publisher',\r\n        name='joint_state_publisher',\r\n        parameters=[{'use_sim_time': use_sim_time}],\r\n        output='screen'\r\n    )\r\n    ld.add_action(joint_state_publisher)\r\n\r\n    # RViz\r\n    rviz = Node(\r\n        package='rviz2',\r\n        executable='rviz2',\r\n        name='rviz2',\r\n        arguments=['-d', PathJoinSubstitution([\r\n            FindPackageShare('my_robot_pkg'),\r\n            'rviz',\r\n            'sensors.rviz'\r\n        ])],\r\n        condition=IfCondition(show_rviz),\r\n        parameters=[{'use_sim_time': use_sim_time}]\r\n    )\r\n    ld.add_action(rviz)\r\n\r\n    return ld\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-3-create-a-sensor-processing-node",children:"Step 3: Create a Sensor Processing Node"}),"\n",(0,i.jsxs)(n.p,{children:["Create ",(0,i.jsx)(n.code,{children:"sensor_processing.py"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom sensor_msgs.msg import Image, Imu\r\nfrom cv_bridge import CvBridge\r\nimport cv2\r\nimport numpy as np\r\n\r\nclass SensorProcessor(Node):\r\n    def __init__(self):\r\n        super().__init__('sensor_processor')\r\n\r\n        # Create subscribers\r\n        self.camera_sub = self.create_subscription(\r\n            Image,\r\n            'image_raw',\r\n            self.camera_callback,\r\n            10\r\n        )\r\n\r\n        self.imu_sub = self.create_subscription(\r\n            Imu,\r\n            'imu',\r\n            self.imu_callback,\r\n            10\r\n        )\r\n\r\n        # Create publishers\r\n        self.image_pub = self.create_publisher(Image, 'processed_image', 10)\r\n\r\n        # Initialize CvBridge\r\n        self.bridge = CvBridge()\r\n\r\n        self.get_logger().info('Sensor Processor Node Started')\r\n\r\n    def camera_callback(self, msg):\r\n        try:\r\n            # Convert ROS Image message to OpenCV image\r\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\r\n\r\n            # Process the image (example: edge detection)\r\n            gray = cv2.cvtColor(cv_image, cv2.COLOR_BGR2GRAY)\r\n            edges = cv2.Canny(gray, 50, 150)\r\n\r\n            # Convert back to ROS Image message\r\n            processed_msg = self.bridge.cv2_to_imgmsg(edges, \"mono8\")\r\n            processed_msg.header = msg.header\r\n\r\n            # Publish processed image\r\n            self.image_pub.publish(processed_msg)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Error processing camera image: {str(e)}')\r\n\r\n    def imu_callback(self, msg):\r\n        # Process IMU data\r\n        orientation = msg.orientation\r\n        angular_velocity = msg.angular_velocity\r\n        linear_acceleration = msg.linear_acceleration\r\n\r\n        # Log some values\r\n        self.get_logger().info(\r\n            f'IMU - Orientation: ({orientation.x:.2f}, {orientation.y:.2f}, {orientation.z:.2f}, {orientation.w:.2f})'\r\n        )\r\n\r\ndef main(args=None):\r\n    rclpy.init(args=args)\r\n    sensor_processor = SensorProcessor()\r\n\r\n    try:\r\n        rclpy.spin(sensor_processor)\r\n    except KeyboardInterrupt:\r\n        pass\r\n    finally:\r\n        sensor_processor.destroy_node()\r\n        rclpy.shutdown()\r\n\r\nif __name__ == '__main__':\r\n    main()\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-4-build-and-run-the-simulation",children:"Step 4: Build and Run the Simulation"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Build your ROS 2 package:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"cd ~/ros2_ws\r\ncolcon build --packages-select my_robot_pkg\r\nsource install/setup.bash\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"2",children:["\n",(0,i.jsx)(n.li,{children:"Launch the simulation:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 launch my_robot_pkg sensor_demo.launch.py\n"})}),"\n",(0,i.jsxs)(n.ol,{start:"3",children:["\n",(0,i.jsx)(n.li,{children:"In another terminal, run the sensor processing node:"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"ros2 run my_robot_pkg sensor_processing\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-5-verify-sensor-data",children:"Step 5: Verify Sensor Data"}),"\n",(0,i.jsx)(n.p,{children:"Check that sensor data is being published:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:'# Check available topics\r\nros2 topic list | grep -E "(image|imu)"\r\n\r\n# View camera feed\r\nros2 run image_view image_view _image:=/image_raw\r\n\r\n# Monitor IMU data\r\nros2 topic echo /imu\n'})}),"\n",(0,i.jsx)(n.h2,{id:"expected-results",children:"Expected Results"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Robot model appears in Gazebo with properly configured sensors"}),"\n",(0,i.jsxs)(n.li,{children:["Camera publishes image data to ",(0,i.jsx)(n.code,{children:"/image_raw"})]}),"\n",(0,i.jsxs)(n.li,{children:["IMU publishes orientation and acceleration data to ",(0,i.jsx)(n.code,{children:"/imu"})]}),"\n",(0,i.jsx)(n.li,{children:"Sensor processing node receives and processes sensor data"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"troubleshooting",children:"Troubleshooting"}),"\n",(0,i.jsx)(n.p,{children:"If sensors don't appear to be publishing data:"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"Check that the Gazebo plugins are properly configured in the URDF"}),"\n",(0,i.jsx)(n.li,{children:"Verify that the robot is spawned correctly in Gazebo"}),"\n",(0,i.jsx)(n.li,{children:"Ensure all required ROS 2 packages are installed"}),"\n",(0,i.jsxs)(n.li,{children:["Check TF transforms using ",(0,i.jsx)(n.code,{children:"ros2 run tf2_tools view_frames"})]}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,i.jsxs)(n.p,{children:["Continue to ",(0,i.jsx)(n.a,{href:"/humanoid-robotics-book/simulation/troubleshooting",children:"Troubleshooting"})," to learn about common simulation issues and solutions."]})]})}function d(e={}){const{wrapper:n}={...(0,o.RP)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(u,{...e})}):u(e)}},8453:(e,n,r)=>{r.d(n,{RP:()=>s});var i=r(6540);const o=i.createContext({});function s(e){const n=i.useContext(o);return i.useMemo(()=>"function"==typeof e?e(n):{...n,...e},[n,e])}}}]);