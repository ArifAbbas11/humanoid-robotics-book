"use strict";(globalThis.webpackChunkhumanoid_robotics_book=globalThis.webpackChunkhumanoid_robotics_book||[]).push([[2228],{3522:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>s,contentTitle:()=>o,default:()=>m,frontMatter:()=>a,metadata:()=>c,toc:()=>l});var r=t(4848),i=t(8453);const a={},o="Voice-to-Action Mapping",c={id:"vla-integration/voice-to-action",title:"Voice-to-Action Mapping",description:"Overview",source:"@site/docs/vla-integration/voice-to-action.md",sourceDirName:"vla-integration",slug:"/vla-integration/voice-to-action",permalink:"/humanoid-robotics-book/vla-integration/voice-to-action",draft:!1,unlisted:!1,editUrl:"https://github.com/ArifAbbas11/humanoid-robotics-book/tree/main/docs/vla-integration/voice-to-action.md",tags:[],version:"current",frontMatter:{},sidebar:"bookSidebar",previous:{title:"Multi-Modal Processing",permalink:"/humanoid-robotics-book/vla-integration/multi-modal"},next:{title:"VLA Capstone Project: Intelligent Humanoid Assistant",permalink:"/humanoid-robotics-book/vla-integration/capstone-project"}},s={},l=[{value:"Overview",id:"overview",level:2},{value:"Voice-to-Action Architecture",id:"voice-to-action-architecture",level:2},{value:"The Mapping Pipeline",id:"the-mapping-pipeline",level:3},{value:"System Components",id:"system-components",level:3},{value:"Natural Language Understanding for Action Mapping",id:"natural-language-understanding-for-action-mapping",level:2},{value:"Command Parsing",id:"command-parsing",level:3},{value:"Intent Classification",id:"intent-classification",level:3},{value:"Action Mapping Strategies",id:"action-mapping-strategies",level:2},{value:"Rule-Based Mapping",id:"rule-based-mapping",level:3},{value:"Machine Learning-Based Mapping",id:"machine-learning-based-mapping",level:3},{value:"Context-Aware Action Mapping",id:"context-aware-action-mapping",level:2},{value:"Environment Context Integration",id:"environment-context-integration",level:3},{value:"Action Execution Planning",id:"action-execution-planning",level:2},{value:"Sequential Action Planning",id:"sequential-action-planning",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Voice-to-Action Node",id:"voice-to-action-node",level:3},{value:"Advanced Mapping Techniques",id:"advanced-mapping-techniques",level:2},{value:"Semantic Action Mapping",id:"semantic-action-mapping",level:3},{value:"Error Handling and Recovery",id:"error-handling-and-recovery",level:2},{value:"Robust Action Mapping",id:"robust-action-mapping",level:3},{value:"Performance Optimization",id:"performance-optimization",level:2},{value:"Efficient Command Processing",id:"efficient-command-processing",level:3},{value:"Quality Assessment",id:"quality-assessment",level:2},{value:"Action Mapping Quality Metrics",id:"action-mapping-quality-metrics",level:3},{value:"Troubleshooting Common Issues",id:"troubleshooting-common-issues",level:2},{value:"Command Understanding Problems",id:"command-understanding-problems",level:3},{value:"Action Execution Problems",id:"action-execution-problems",level:3},{value:"Best Practices",id:"best-practices",level:2},{value:"System Design",id:"system-design",level:3},{value:"Performance Considerations",id:"performance-considerations",level:3},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.RP)(),...n.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(e.h1,{id:"voice-to-action-mapping",children:"Voice-to-Action Mapping"}),"\n",(0,r.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsx)(e.p,{children:"Voice-to-Action mapping is the process of converting natural language voice commands into executable robot actions. This critical component of Vision-Language-Action (VLA) systems bridges human communication with robot behavior, enabling intuitive human-robot interaction through speech."}),"\n",(0,r.jsx)(e.h2,{id:"voice-to-action-architecture",children:"Voice-to-Action Architecture"}),"\n",(0,r.jsx)(e.h3,{id:"the-mapping-pipeline",children:"The Mapping Pipeline"}),"\n",(0,r.jsx)(e.p,{children:"The voice-to-action pipeline typically follows this sequence:"}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Voice Input"}),": User speaks a command to the robot"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Speech Recognition"}),": Converts speech to text"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Natural Language Understanding"}),": Interprets the meaning of the command"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action Mapping"}),": Maps the understood command to specific robot actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action Validation"}),": Ensures actions are safe and feasible"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action Execution"}),": Executes the mapped actions on the robot"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Feedback"}),": Provides feedback to the user about the execution"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"system-components",children:"System Components"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Voice Recognition Module"}),": Converts speech to text"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Language Understanding Module"}),": Parses and interprets commands"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action Mapping Engine"}),": Maps commands to robot actions"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Action Executor"}),": Executes the actions on the robot"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Feedback System"}),": Communicates execution status to the user"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"natural-language-understanding-for-action-mapping",children:"Natural Language Understanding for Action Mapping"}),"\n",(0,r.jsx)(e.h3,{id:"command-parsing",children:"Command Parsing"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import re\r\nfrom typing import Dict, List, Tuple\r\n\r\nclass CommandParser:\r\n    def __init__(self):\r\n        # Define action patterns\r\n        self.action_patterns = {\r\n            'navigation': [\r\n                r'go to (.+)',\r\n                r'move to (.+)',\r\n                r'walk to (.+)',\r\n                r'navigate to (.+)',\r\n                r'go (.+)'\r\n            ],\r\n            'manipulation': [\r\n                r'pick up (.+)',\r\n                r'grasp (.+)',\r\n                r'take (.+)',\r\n                r'get (.+)',\r\n                r'put (.+) (?:on|in) (.+)',\r\n                r'place (.+) (?:on|in) (.+)'\r\n            ],\r\n            'interaction': [\r\n                r'greet (.+)',\r\n                r'say hello to (.+)',\r\n                r'wave to (.+)',\r\n                r'nod to (.+)'\r\n            ],\r\n            'information': [\r\n                r'what is (.+)',\r\n                r'where is (.+)',\r\n                r'find (.+)',\r\n                r'show me (.+)'\r\n            ]\r\n        }\r\n\r\n    def parse_command(self, text: str) -> Dict:\r\n        \"\"\"Parse natural language command into structured format\"\"\"\r\n        text_lower = text.lower().strip()\r\n\r\n        for action_type, patterns in self.action_patterns.items():\r\n            for pattern in patterns:\r\n                match = re.search(pattern, text_lower)\r\n                if match:\r\n                    params = match.groups()\r\n                    return {\r\n                        'action_type': action_type,\r\n                        'action_pattern': pattern,\r\n                        'parameters': params,\r\n                        'original_text': text,\r\n                        'confidence': 0.9  # High confidence for regex match\r\n                    }\r\n\r\n        # If no pattern matches, return unknown\r\n        return {\r\n            'action_type': 'unknown',\r\n            'action_pattern': None,\r\n            'parameters': [],\r\n            'original_text': text,\r\n            'confidence': 0.0\r\n        }\r\n\r\n    def extract_entities(self, text: str) -> Dict[str, List[str]]:\r\n        \"\"\"Extract entities like objects, locations, people from text\"\"\"\r\n        entities = {\r\n            'objects': [],\r\n            'locations': [],\r\n            'people': [],\r\n            'actions': []\r\n        }\r\n\r\n        # Simple keyword-based entity extraction\r\n        object_keywords = ['cup', 'book', 'ball', 'bottle', 'box', 'chair', 'table']\r\n        location_keywords = ['kitchen', 'living room', 'bedroom', 'office', 'hall', 'door']\r\n        people_keywords = ['person', 'man', 'woman', 'child', 'me', 'you']\r\n\r\n        text_lower = text.lower()\r\n        words = text_lower.split()\r\n\r\n        for keyword in object_keywords:\r\n            if keyword in text_lower:\r\n                entities['objects'].append(keyword)\r\n\r\n        for keyword in location_keywords:\r\n            if keyword in text_lower:\r\n                entities['locations'].append(keyword)\r\n\r\n        for keyword in people_keywords:\r\n            if keyword in text_lower:\r\n                entities['people'].append(keyword)\r\n\r\n        return entities\n"})}),"\n",(0,r.jsx)(e.h3,{id:"intent-classification",children:"Intent Classification"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class IntentClassifier:\r\n    def __init__(self):\r\n        self.intent_keywords = {\r\n            'navigation': ['go', 'move', 'walk', 'navigate', 'to', 'toward', 'towards'],\r\n            'manipulation': ['pick', 'grasp', 'take', 'get', 'put', 'place', 'hold', 'drop'],\r\n            'interaction': ['greet', 'hello', 'wave', 'talk', 'speak', 'chat'],\r\n            'information': ['what', 'where', 'find', 'show', 'tell', 'describe']\r\n        }\r\n\r\n    def classify_intent(self, text: str) -> str:\r\n        \"\"\"Classify the intent of a voice command\"\"\"\r\n        text_lower = text.lower()\r\n        scores = {}\r\n\r\n        for intent, keywords in self.intent_keywords.items():\r\n            score = sum(1 for keyword in keywords if keyword in text_lower)\r\n            scores[intent] = score\r\n\r\n        # Return intent with highest score\r\n        if scores:\r\n            return max(scores, key=scores.get)\r\n        return 'unknown'\n"})}),"\n",(0,r.jsx)(e.h2,{id:"action-mapping-strategies",children:"Action Mapping Strategies"}),"\n",(0,r.jsx)(e.h3,{id:"rule-based-mapping",children:"Rule-Based Mapping"}),"\n",(0,r.jsx)(e.p,{children:"Simple rule-based approach for mapping commands to actions:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class RuleBasedActionMapper:\r\n    def __init__(self):\r\n        self.action_mapping_rules = {\r\n            # Navigation commands\r\n            ('navigation', 'go to'): self.map_navigation,\r\n            ('navigation', 'move to'): self.map_navigation,\r\n            ('navigation', 'walk to'): self.map_navigation,\r\n\r\n            # Manipulation commands\r\n            ('manipulation', 'pick up'): self.map_manipulation_pick,\r\n            ('manipulation', 'grasp'): self.map_manipulation_grasp,\r\n            ('manipulation', 'put'): self.map_manipulation_place,\r\n\r\n            # Interaction commands\r\n            ('interaction', 'greet'): self.map_interaction_greet,\r\n            ('interaction', 'wave'): self.map_interaction_wave,\r\n        }\r\n\r\n    def map_action(self, parsed_command: Dict) -> List[Dict]:\r\n        \"\"\"Map parsed command to robot actions\"\"\"\r\n        action_type = parsed_command['action_type']\r\n        pattern = parsed_command['action_pattern']\r\n\r\n        key = (action_type, self.extract_action_from_pattern(pattern))\r\n\r\n        if key in self.action_mapping_rules:\r\n            return self.action_mapping_rules[key](parsed_command)\r\n        else:\r\n            return self.default_mapping(parsed_command)\r\n\r\n    def extract_action_from_pattern(self, pattern: str) -> str:\r\n        \"\"\"Extract action from regex pattern\"\"\"\r\n        # Simple extraction - in practice, this would be more sophisticated\r\n        parts = pattern.split()\r\n        if parts:\r\n            return parts[0]\r\n        return pattern\r\n\r\n    def map_navigation(self, parsed_command: Dict) -> List[Dict]:\r\n        \"\"\"Map navigation commands to robot actions\"\"\"\r\n        destination = parsed_command['parameters'][0] if parsed_command['parameters'] else None\r\n\r\n        actions = [{\r\n            'action_type': 'navigation',\r\n            'action_name': 'navigate_to',\r\n            'parameters': {\r\n                'destination': destination,\r\n                'speed': 'normal'\r\n            },\r\n            'description': f'Navigating to {destination}'\r\n        }]\r\n\r\n        return actions\r\n\r\n    def map_manipulation_pick(self, parsed_command: Dict) -> List[Dict]:\r\n        \"\"\"Map pick-up commands to robot actions\"\"\"\r\n        object_to_pick = parsed_command['parameters'][0] if parsed_command['parameters'] else None\r\n\r\n        actions = [\r\n            {\r\n                'action_type': 'navigation',\r\n                'action_name': 'navigate_to_object',\r\n                'parameters': {\r\n                    'object': object_to_pick,\r\n                    'approach_distance': 0.5\r\n                },\r\n                'description': f'Navigating to {object_to_pick}'\r\n            },\r\n            {\r\n                'action_type': 'manipulation',\r\n                'action_name': 'grasp_object',\r\n                'parameters': {\r\n                    'object': object_to_pick\r\n                },\r\n                'description': f'Grasping {object_to_pick}'\r\n            }\r\n        ]\r\n\r\n        return actions\r\n\r\n    def default_mapping(self, parsed_command: Dict) -> List[Dict]:\r\n        \"\"\"Default mapping for unknown commands\"\"\"\r\n        return [{\r\n            'action_type': 'unknown',\r\n            'action_name': 'unknown_command',\r\n            'parameters': {},\r\n            'description': f\"Unknown command: {parsed_command['original_text']}\"\r\n        }]\n"})}),"\n",(0,r.jsx)(e.h3,{id:"machine-learning-based-mapping",children:"Machine Learning-Based Mapping"}),"\n",(0,r.jsx)(e.p,{children:"Using neural networks for more sophisticated mapping:"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import torch\r\nimport torch.nn as nn\r\nfrom transformers import AutoTokenizer, AutoModel\r\n\r\nclass MLActionMapper(nn.Module):\r\n    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_actions):\r\n        super().__init__()\r\n\r\n        # Text encoding\r\n        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\r\n        self.text_encoder = AutoModel.from_pretrained('bert-base-uncased')\r\n\r\n        # Action prediction head\r\n        self.action_classifier = nn.Sequential(\r\n            nn.Linear(768, hidden_dim),  # BERT hidden size is 768\r\n            nn.ReLU(),\r\n            nn.Dropout(0.1),\r\n            nn.Linear(hidden_dim, num_actions)\r\n        )\r\n\r\n        # Action parameter prediction\r\n        self.param_predictor = nn.Sequential(\r\n            nn.Linear(768, hidden_dim),\r\n            nn.ReLU(),\r\n            nn.Dropout(0.1),\r\n            nn.Linear(hidden_dim, 128)  # Predict 128 parameters (flexible)\r\n        )\r\n\r\n    def forward(self, text_inputs):\r\n        \"\"\"Forward pass through the action mapping network\"\"\"\r\n        # Encode text\r\n        encoded = self.text_encoder(**text_inputs)\r\n        pooled_output = encoded.pooler_output  # [batch_size, 768]\r\n\r\n        # Predict action\r\n        action_logits = self.action_classifier(pooled_output)\r\n        action_probs = torch.softmax(action_logits, dim=-1)\r\n\r\n        # Predict parameters\r\n        param_logits = self.param_predictor(pooled_output)\r\n\r\n        return action_probs, param_logits\r\n\r\n    def map_command(self, text: str):\r\n        \"\"\"Map text command to action using the neural network\"\"\"\r\n        # Tokenize input\r\n        inputs = self.tokenizer(\r\n            text,\r\n            return_tensors='pt',\r\n            padding=True,\r\n            truncation=True,\r\n            max_length=128\r\n        )\r\n\r\n        # Get predictions\r\n        action_probs, param_logits = self.forward(inputs)\r\n\r\n        # Decode predictions to action\r\n        predicted_action = torch.argmax(action_probs, dim=-1).item()\r\n        predicted_params = param_logits.detach().cpu().numpy()\r\n\r\n        return {\r\n            'action_id': predicted_action,\r\n            'action_params': predicted_params,\r\n            'confidence': action_probs.max().item()\r\n        }\n"})}),"\n",(0,r.jsx)(e.h2,{id:"context-aware-action-mapping",children:"Context-Aware Action Mapping"}),"\n",(0,r.jsx)(e.h3,{id:"environment-context-integration",children:"Environment Context Integration"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class ContextAwareActionMapper:\r\n    def __init__(self):\r\n        self.knowledge_base = KnowledgeBase()\r\n        self.vision_processor = VisionProcessor()\r\n        self.action_validator = ActionValidator()\r\n\r\n    def map_with_context(self, command: str, environment_context: Dict):\r\n        \"\"\"Map command considering environmental context\"\"\"\r\n        # Parse the command\r\n        parsed_command = self.parse_command(command)\r\n\r\n        # Get current environment state\r\n        current_state = self.get_environment_state(environment_context)\r\n\r\n        # Map command with context awareness\r\n        raw_actions = self.map_command_to_actions(parsed_command)\r\n\r\n        # Validate actions against current state\r\n        validated_actions = self.validate_actions(raw_actions, current_state)\r\n\r\n        # Adapt actions based on context\r\n        adapted_actions = self.adapt_actions_to_context(\r\n            validated_actions,\r\n            current_state,\r\n            parsed_command\r\n        )\r\n\r\n        return adapted_actions\r\n\r\n    def get_environment_state(self, context: Dict) -> Dict:\r\n        \"\"\"Extract current environment state from context\"\"\"\r\n        state = {\r\n            'robot_location': context.get('robot_location'),\r\n            'detected_objects': context.get('detected_objects', []),\r\n            'reachable_objects': context.get('reachable_objects', []),\r\n            'navigable_areas': context.get('navigable_areas', []),\r\n            'human_positions': context.get('humans', []),\r\n            'robot_state': context.get('robot_state', {})\r\n        }\r\n        return state\r\n\r\n    def validate_actions(self, actions: List[Dict], state: Dict) -> List[Dict]:\r\n        \"\"\"Validate actions against current environment state\"\"\"\r\n        valid_actions = []\r\n\r\n        for action in actions:\r\n            if self.action_validator.is_valid(action, state):\r\n                valid_actions.append(action)\r\n            else:\r\n                # Try to adapt the action\r\n                adapted = self.adapt_invalid_action(action, state)\r\n                if adapted:\r\n                    valid_actions.append(adapted)\r\n\r\n        return valid_actions\r\n\r\n    def adapt_actions_to_context(self, actions: List[Dict], state: Dict, command: Dict) -> List[Dict]:\r\n        \"\"\"Adapt actions based on environmental context\"\"\"\r\n        adapted_actions = []\r\n\r\n        for action in actions:\r\n            if action['action_type'] == 'navigation':\r\n                # Check if destination is navigable\r\n                destination = action['parameters'].get('destination')\r\n                if destination:\r\n                    # Resolve destination to specific location\r\n                    resolved_location = self.resolve_location(destination, state)\r\n                    action['parameters']['destination'] = resolved_location\r\n\r\n            elif action['action_type'] == 'manipulation':\r\n                # Check if object is reachable\r\n                target_object = action['parameters'].get('object')\r\n                if target_object:\r\n                    # Find the specific object instance\r\n                    object_instance = self.find_object_instance(target_object, state)\r\n                    if object_instance:\r\n                        action['parameters']['object_pose'] = object_instance['pose']\r\n\r\n            adapted_actions.append(action)\r\n\r\n        return adapted_actions\r\n\r\n    def resolve_location(self, location_desc: str, state: Dict) -> str:\r\n        \"\"\"Resolve location description to specific coordinates\"\"\"\r\n        # Look up in knowledge base\r\n        known_locations = self.knowledge_base.get_locations()\r\n\r\n        for loc_name, loc_info in known_locations.items():\r\n            if location_desc.lower() in loc_name.lower():\r\n                return loc_info['coordinates']\r\n\r\n        # If not found, try to find in current context\r\n        for nav_area in state['navigable_areas']:\r\n            if location_desc.lower() in nav_area.get('name', '').lower():\r\n                return nav_area['coordinates']\r\n\r\n        # Default to current location if can't resolve\r\n        return state['robot_location']\n"})}),"\n",(0,r.jsx)(e.h2,{id:"action-execution-planning",children:"Action Execution Planning"}),"\n",(0,r.jsx)(e.h3,{id:"sequential-action-planning",children:"Sequential Action Planning"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class ActionExecutionPlanner:\r\n    def __init__(self):\r\n        self.action_library = self.load_action_library()\r\n        self.precondition_checker = PreconditionChecker()\r\n        self.effect_predictor = EffectPredictor()\r\n\r\n    def plan_execution_sequence(self, actions: List[Dict]) -> List[Dict]:\r\n        \"\"\"Plan sequence of actions for execution\"\"\"\r\n        execution_plan = []\r\n\r\n        for action in actions:\r\n            # Check preconditions\r\n            if not self.precondition_checker.check(action):\r\n                # Try to satisfy preconditions\r\n                precondition_actions = self.satisfy_preconditions(action)\r\n                execution_plan.extend(precondition_actions)\r\n\r\n            # Add the main action\r\n            execution_plan.append(action)\r\n\r\n            # Update expected state effects\r\n            self.effect_predictor.update_state(action)\r\n\r\n        return execution_plan\r\n\r\n    def satisfy_preconditions(self, action: Dict) -> List[Dict]:\r\n        \"\"\"Generate actions to satisfy preconditions for a given action\"\"\"\r\n        preconditions = self.action_library[action['action_name']].get('preconditions', [])\r\n        precondition_actions = []\r\n\r\n        for precondition in preconditions:\r\n            if not self.precondition_checker.is_satisfied(precondition):\r\n                # Generate action to satisfy precondition\r\n                satisfying_action = self.generate_satisfying_action(precondition)\r\n                if satisfying_action:\r\n                    precondition_actions.append(satisfying_action)\r\n\r\n        return precondition_actions\r\n\r\n    def generate_satisfying_action(self, precondition: Dict) -> Dict:\r\n        \"\"\"Generate action to satisfy a specific precondition\"\"\"\r\n        # Example: if precondition is \"robot_at_location\", generate navigation action\r\n        if precondition.get('type') == 'robot_at_location':\r\n            return {\r\n                'action_type': 'navigation',\r\n                'action_name': 'navigate_to',\r\n                'parameters': {\r\n                    'destination': precondition['location']\r\n                },\r\n                'description': f'Navigating to satisfy precondition: at {precondition[\"location\"]}'\r\n            }\r\n\r\n        # Add more precondition types as needed\r\n        return None\n"})}),"\n",(0,r.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,r.jsx)(e.h3,{id:"voice-to-action-node",children:"Voice-to-Action Node"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"import rclpy\r\nfrom rclpy.node import Node\r\nfrom std_msgs.msg import String\r\nfrom geometry_msgs.msg import Pose\r\nfrom vla_msgs.msg import ActionCommand, ActionResult\r\nfrom vla_msgs.srv import ExecuteAction\r\n\r\nclass VoiceToActionNode(Node):\r\n    def __init__(self):\r\n        super().__init__('voice_to_action_node')\r\n\r\n        # Subscribers\r\n        self.voice_sub = self.create_subscription(\r\n            String,\r\n            'recognized_text',\r\n            self.voice_callback,\r\n            10\r\n        )\r\n\r\n        # Publishers\r\n        self.action_pub = self.create_publisher(\r\n            ActionCommand,\r\n            'robot_action_commands',\r\n            10\r\n        )\r\n\r\n        self.feedback_pub = self.create_publisher(\r\n            String,\r\n            'action_feedback',\r\n            10\r\n        )\r\n\r\n        # Services\r\n        self.execute_service = self.create_service(\r\n            ExecuteAction,\r\n            'execute_mapped_action',\r\n            self.execute_action_callback\r\n        )\r\n\r\n        # Initialize action mapping components\r\n        self.command_parser = CommandParser()\r\n        self.intent_classifier = IntentClassifier()\r\n        self.action_mapper = RuleBasedActionMapper()\r\n        self.context_aware_mapper = ContextAwareActionMapper()\r\n\r\n        self.get_logger().info('Voice-to-Action Node initialized')\r\n\r\n    def voice_callback(self, msg: String):\r\n        \"\"\"Process voice command from speech recognition\"\"\"\r\n        command_text = msg.data\r\n        self.get_logger().info(f'Received voice command: {command_text}')\r\n\r\n        try:\r\n            # Parse the command\r\n            parsed_command = self.command_parser.parse_command(command_text)\r\n\r\n            if parsed_command['confidence'] > 0.5:  # Threshold\r\n                # Map to actions\r\n                actions = self.action_mapper.map_action(parsed_command)\r\n\r\n                # Publish actions for execution\r\n                for action in actions:\r\n                    action_msg = self.create_action_message(action)\r\n                    self.action_pub.publish(action_msg)\r\n\r\n                # Provide feedback\r\n                feedback_msg = String()\r\n                feedback_msg.data = f\"Understood command: {command_text}, executing {len(actions)} actions\"\r\n                self.feedback_pub.publish(feedback_msg)\r\n\r\n            else:\r\n                # Low confidence - ask for clarification\r\n                feedback_msg = String()\r\n                feedback_msg.data = f\"Sorry, I didn't understand: {command_text}. Could you repeat?\"\r\n                self.feedback_pub.publish(feedback_msg)\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Error processing voice command: {e}')\r\n            feedback_msg = String()\r\n            feedback_msg.data = f\"Error processing command: {e}\"\r\n            self.feedback_pub.publish(feedback_msg)\r\n\r\n    def execute_action_callback(self, request, response):\r\n        \"\"\"Service callback for executing mapped actions\"\"\"\r\n        try:\r\n            # Get current context (would typically come from other nodes)\r\n            context = self.get_current_context()\r\n\r\n            # Map the command with context\r\n            actions = self.context_aware_mapper.map_with_context(\r\n                request.command,\r\n                context\r\n            )\r\n\r\n            # Execute actions\r\n            execution_results = []\r\n            for action in actions:\r\n                result = self.execute_single_action(action)\r\n                execution_results.append(result)\r\n\r\n            # Set response\r\n            response.success = all(result['success'] for result in execution_results)\r\n            response.results = execution_results\r\n            response.message = \"Actions executed successfully\" if response.success else \"Some actions failed\"\r\n\r\n        except Exception as e:\r\n            self.get_logger().error(f'Action execution failed: {e}')\r\n            response.success = False\r\n            response.message = f\"Execution failed: {e}\"\r\n\r\n        return response\r\n\r\n    def get_current_context(self) -> Dict:\r\n        \"\"\"Get current environment context\"\"\"\r\n        # This would typically subscribe to various sensor topics\r\n        # and aggregate the information\r\n        return {\r\n            'robot_location': 'kitchen',\r\n            'detected_objects': ['red cup', 'blue book'],\r\n            'reachable_objects': ['red cup'],\r\n            'navigable_areas': ['kitchen', 'living room'],\r\n            'robot_state': {'battery': 85, 'gripper': 'open'}\r\n        }\r\n\r\n    def execute_single_action(self, action: Dict) -> Dict:\r\n        \"\"\"Execute a single action\"\"\"\r\n        # This would typically call other ROS services/nodes\r\n        # to execute the specific action\r\n        return {\r\n            'action_name': action['action_name'],\r\n            'success': True,\r\n            'message': f\"Executed {action['action_name']}\",\r\n            'execution_time': 0.0\r\n        }\r\n\r\n    def create_action_message(self, action: Dict) -> ActionCommand:\r\n        \"\"\"Create ROS message from action dictionary\"\"\"\r\n        action_msg = ActionCommand()\r\n        action_msg.action_type = action['action_type']\r\n        action_msg.action_name = action['action_name']\r\n        action_msg.parameters = str(action['parameters'])  # Convert to string for simplicity\r\n        action_msg.description = action['description']\r\n        action_msg.header.stamp = self.get_clock().now().to_msg()\r\n        return action_msg\n"})}),"\n",(0,r.jsx)(e.h2,{id:"advanced-mapping-techniques",children:"Advanced Mapping Techniques"}),"\n",(0,r.jsx)(e.h3,{id:"semantic-action-mapping",children:"Semantic Action Mapping"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class SemanticActionMapper:\r\n    def __init__(self):\r\n        self.semantic_parser = SemanticParser()\r\n        self.action_space = ActionSpace()\r\n        self.reasoning_engine = ReasoningEngine()\r\n\r\n    def map_with_semantics(self, command: str) -> List[Dict]:\r\n        \"\"\"Map command using semantic understanding\"\"\"\r\n        # Parse command semantically\r\n        semantic_structure = self.semantic_parser.parse(command)\r\n\r\n        # Ground semantics in robot capabilities\r\n        grounded_actions = self.ground_semantics(semantic_structure)\r\n\r\n        # Reason about the best action sequence\r\n        reasoned_actions = self.reasoning_engine.reason(\r\n            grounded_actions,\r\n            semantic_structure\r\n        )\r\n\r\n        return reasoned_actions\r\n\r\n    def ground_semantics(self, semantic_structure: Dict) -> List[Dict]:\r\n        \"\"\"Ground semantic structure in robot action space\"\"\"\r\n        actions = []\r\n\r\n        # Example semantic structure processing\r\n        if semantic_structure.get('action') == 'transport':\r\n            source = semantic_structure.get('source')\r\n            target = semantic_structure.get('target')\r\n            object = semantic_structure.get('object')\r\n\r\n            actions = [\r\n                {\r\n                    'action_type': 'navigation',\r\n                    'action_name': 'navigate_to',\r\n                    'parameters': {'destination': source}\r\n                },\r\n                {\r\n                    'action_type': 'manipulation',\r\n                    'action_name': 'grasp',\r\n                    'parameters': {'object': object}\r\n                },\r\n                {\r\n                    'action_type': 'navigation',\r\n                    'action_name': 'navigate_to',\r\n                    'parameters': {'destination': target}\r\n                },\r\n                {\r\n                    'action_type': 'manipulation',\r\n                    'action_name': 'place',\r\n                    'parameters': {'object': object}\r\n                }\r\n            ]\r\n\r\n        return actions\n"})}),"\n",(0,r.jsx)(e.h2,{id:"error-handling-and-recovery",children:"Error Handling and Recovery"}),"\n",(0,r.jsx)(e.h3,{id:"robust-action-mapping",children:"Robust Action Mapping"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:"class RobustActionMapper:\r\n    def __init__(self):\r\n        self.fallback_strategies = [\r\n            self.fallback_to_simple_navigation,\r\n            self.fallback_to_manual_control_request,\r\n            self.fallback_to_context_query\r\n        ]\r\n\r\n    def map_with_fallback(self, command: str, context: Dict) -> List[Dict]:\r\n        \"\"\"Map command with fallback strategies\"\"\"\r\n        try:\r\n            # Primary mapping\r\n            actions = self.primary_mapping(command, context)\r\n\r\n            # Validate actions\r\n            if self.validate_actions(actions, context):\r\n                return actions\r\n        except Exception as e:\r\n            self.get_logger().warning(f'Primary mapping failed: {e}')\r\n\r\n        # Try fallback strategies\r\n        for fallback_strategy in self.fallback_strategies:\r\n            try:\r\n                fallback_actions = fallback_strategy(command, context)\r\n                if fallback_actions and self.validate_actions(fallback_actions, context):\r\n                    return fallback_actions\r\n            except Exception as e:\r\n                self.get_logger().warning(f'Fallback strategy failed: {e}')\r\n                continue\r\n\r\n        # If all strategies fail, return error action\r\n        return [{\r\n            'action_type': 'error',\r\n            'action_name': 'unknown_command',\r\n            'parameters': {'original_command': command},\r\n            'description': f'Unable to map command: {command}'\r\n        }]\r\n\r\n    def validate_actions(self, actions: List[Dict], context: Dict) -> bool:\r\n        \"\"\"Validate that actions are feasible in current context\"\"\"\r\n        for action in actions:\r\n            if not self.is_action_feasible(action, context):\r\n                return False\r\n        return True\r\n\r\n    def is_action_feasible(self, action: Dict, context: Dict) -> bool:\r\n        \"\"\"Check if action is feasible in current context\"\"\"\r\n        # Check robot capabilities\r\n        if not self.has_capability(action['action_name']):\r\n            return False\r\n\r\n        # Check safety constraints\r\n        if not self.is_safe(action, context):\r\n            return False\r\n\r\n        # Check resource constraints\r\n        if not self.has_resources(action, context):\r\n            return False\r\n\r\n        return True\r\n\r\n    def fallback_to_simple_navigation(self, command: str, context: Dict) -> List[Dict]:\r\n        \"\"\"Fallback to simple navigation if command is unclear\"\"\"\r\n        # Extract potential location from command\r\n        location = self.extract_location(command)\r\n        if location:\r\n            return [{\r\n                'action_type': 'navigation',\r\n                'action_name': 'navigate_to',\r\n                'parameters': {'destination': location},\r\n                'description': f'Navigating to {location} (fallback)'\r\n            }]\r\n        return []\r\n\r\n    def extract_location(self, command: str) -> str:\r\n        \"\"\"Extract location from command\"\"\"\r\n        # Simple keyword-based extraction\r\n        locations = ['kitchen', 'living room', 'bedroom', 'office', 'hall']\r\n        command_lower = command.lower()\r\n\r\n        for location in locations:\r\n            if location in command_lower:\r\n                return location\r\n\r\n        return None\n"})}),"\n",(0,r.jsx)(e.h2,{id:"performance-optimization",children:"Performance Optimization"}),"\n",(0,r.jsx)(e.h3,{id:"efficient-command-processing",children:"Efficient Command Processing"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class EfficientCommandProcessor:\r\n    def __init__(self):\r\n        self.command_cache = {}\r\n        self.pattern_matcher = OptimizedPatternMatcher()\r\n        self.command_templates = self.load_command_templates()\r\n\r\n    def process_command_efficiently(self, command: str) -> List[Dict]:\r\n        """Process command efficiently with caching and optimization"""\r\n        # Check cache first\r\n        if command in self.command_cache:\r\n            cached_result, timestamp = self.command_cache[command]\r\n            if time.time() - timestamp < 300:  # 5 minute cache\r\n                return cached_result\r\n\r\n        # Use optimized pattern matching\r\n        matched_template = self.pattern_matcher.match(command)\r\n\r\n        if matched_template:\r\n            actions = self.generate_actions_from_template(matched_template)\r\n        else:\r\n            # Fall back to full processing\r\n            actions = self.full_command_processing(command)\r\n\r\n        # Cache result\r\n        self.cache_command_result(command, actions)\r\n\r\n        return actions\r\n\r\n    def generate_actions_from_template(self, template: Dict) -> List[Dict]:\r\n        """Generate actions from matched template"""\r\n        # Template-based action generation is faster than parsing\r\n        return template[\'actions\']\r\n\r\n    def cache_command_result(self, command: str, result: List[Dict]):\r\n        """Cache command processing result"""\r\n        if len(self.command_cache) > 100:  # Limit cache size\r\n            # Remove oldest entries\r\n            oldest_key = next(iter(self.command_cache))\r\n            del self.command_cache[oldest_key]\r\n\r\n        self.command_cache[command] = (result, time.time())\n'})}),"\n",(0,r.jsx)(e.h2,{id:"quality-assessment",children:"Quality Assessment"}),"\n",(0,r.jsx)(e.h3,{id:"action-mapping-quality-metrics",children:"Action Mapping Quality Metrics"}),"\n",(0,r.jsx)(e.pre,{children:(0,r.jsx)(e.code,{className:"language-python",children:'class ActionMappingQualityAssessment:\r\n    def __init__(self):\r\n        self.metrics = {\r\n            \'accuracy\': 0,\r\n            \'completeness\': 0,\r\n            \'safety\': 0,\r\n            \'efficiency\': 0\r\n        }\r\n\r\n    def assess_mapping_quality(self, command: str, mapped_actions: List[Dict], expected_actions: List[Dict] = None) -> Dict:\r\n        """Assess quality of action mapping"""\r\n        quality_metrics = {}\r\n\r\n        # Accuracy: How well do mapped actions match expected actions?\r\n        if expected_actions:\r\n            quality_metrics[\'accuracy\'] = self.compute_accuracy(\r\n                mapped_actions, expected_actions\r\n            )\r\n\r\n        # Completeness: Do mapped actions cover the full intent?\r\n        quality_metrics[\'completeness\'] = self.compute_completeness(\r\n            command, mapped_actions\r\n        )\r\n\r\n        # Safety: Are mapped actions safe to execute?\r\n        quality_metrics[\'safety\'] = self.compute_safety_score(mapped_actions)\r\n\r\n        # Efficiency: How many actions are needed?\r\n        quality_metrics[\'efficiency\'] = self.compute_efficiency(mapped_actions)\r\n\r\n        return quality_metrics\r\n\r\n    def compute_accuracy(self, mapped: List[Dict], expected: List[Dict]) -> float:\r\n        """Compute accuracy of action mapping"""\r\n        if not expected:\r\n            return 0.0\r\n\r\n        correct_actions = 0\r\n        for exp_action in expected:\r\n            for map_action in mapped:\r\n                if (exp_action[\'action_name\'] == map_action[\'action_name\'] and\r\n                    self.parameters_match(exp_action[\'parameters\'], map_action[\'parameters\'])):\r\n                    correct_actions += 1\r\n                    break\r\n\r\n        return correct_actions / len(expected)\r\n\r\n    def compute_completeness(self, command: str, actions: List[Dict]) -> float:\r\n        """Compute how completely the command intent is addressed"""\r\n        # This would involve analyzing whether the actions address all aspects of the command\r\n        return 1.0 if actions else 0.0\r\n\r\n    def compute_safety_score(self, actions: List[Dict]) -> float:\r\n        """Compute safety score for the action sequence"""\r\n        # Check each action for safety\r\n        safe_actions = sum(1 for action in actions if self.is_action_safe(action))\r\n        return safe_actions / len(actions) if actions else 0.0\r\n\r\n    def parameters_match(self, params1: Dict, params2: Dict, threshold: float = 0.8) -> bool:\r\n        """Check if parameters approximately match"""\r\n        # Implementation would compare parameter values\r\n        return True\n'})}),"\n",(0,r.jsx)(e.h2,{id:"troubleshooting-common-issues",children:"Troubleshooting Common Issues"}),"\n",(0,r.jsx)(e.h3,{id:"command-understanding-problems",children:"Command Understanding Problems"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Commands are not being understood correctly."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Expand command pattern database"}),"\n",(0,r.jsx)(e.li,{children:"Improve natural language preprocessing"}),"\n",(0,r.jsx)(e.li,{children:"Add context-aware disambiguation"}),"\n",(0,r.jsx)(e.li,{children:"Implement user feedback learning"}),"\n"]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Ambiguous commands lead to incorrect actions."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Implement clarification requests"}),"\n",(0,r.jsx)(e.li,{children:"Use confidence thresholds"}),"\n",(0,r.jsx)(e.li,{children:"Add disambiguation strategies"}),"\n",(0,r.jsx)(e.li,{children:"Maintain command history for context"}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"action-execution-problems",children:"Action Execution Problems"}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Issue"}),": Mapped actions fail during execution."]}),"\n",(0,r.jsxs)(e.p,{children:[(0,r.jsx)(e.strong,{children:"Solutions"}),":"]}),"\n",(0,r.jsxs)(e.ol,{children:["\n",(0,r.jsx)(e.li,{children:"Improve action validation before execution"}),"\n",(0,r.jsx)(e.li,{children:"Add simulation-based verification"}),"\n",(0,r.jsx)(e.li,{children:"Implement robust error handling"}),"\n",(0,r.jsx)(e.li,{children:"Use gradual action refinement"}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(e.h3,{id:"system-design",children:"System Design"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Modular Architecture"}),": Keep command parsing, mapping, and execution separate"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Fallback Mechanisms"}),": Always have fallback strategies for failed mappings"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"User Feedback"}),": Provide clear feedback about command understanding"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Safety First"}),": Validate all actions before execution"]}),"\n"]}),"\n",(0,r.jsx)(e.h3,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,r.jsxs)(e.ul,{children:["\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Caching"}),": Cache frequently used command mappings"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Optimization"}),": Use efficient pattern matching algorithms"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Parallel Processing"}),": Process multiple aspects of commands in parallel"]}),"\n",(0,r.jsxs)(e.li,{children:[(0,r.jsx)(e.strong,{children:"Real-time Constraints"}),": Ensure mapping completes within real-time requirements"]}),"\n"]}),"\n",(0,r.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,r.jsxs)(e.p,{children:["Continue to ",(0,r.jsx)(e.a,{href:"/humanoid-robotics-book/vla-integration/capstone-project",children:"Capstone Project"})," to apply all VLA integration concepts in a comprehensive humanoid robotics project."]})]})}function m(n={}){const{wrapper:e}={...(0,i.RP)(),...n.components};return e?(0,r.jsx)(e,{...n,children:(0,r.jsx)(d,{...n})}):d(n)}},8453:(n,e,t)=>{t.d(e,{RP:()=>a});var r=t(6540);const i=r.createContext({});function a(n){const e=r.useContext(i);return r.useMemo(()=>"function"==typeof n?n(e):{...e,...n},[e,n])}}}]);